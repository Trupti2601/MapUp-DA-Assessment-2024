{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3XARR1fi4pAZ"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "def reverse_by_n_elements(lst: List[int], n: int) -> List[int]:\n",
        "  for i in range(0, len(lst), n):\n",
        "    start = i\n",
        "    end = min(i + n - 1, len(lst) - 1)\n",
        "    while start < end:\n",
        "      lst[start], lst[end] = lst[end], lst[start]\n",
        "      start += 1\n",
        "      end -= 1\n",
        "\n",
        "  return lst\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_by_n_elements([1,2,3,4,5,6,7], 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFaAjrLm4xvK",
        "outputId": "f970a3e0-90a0-4b17-e1d3-679544ce407e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 2, 1, 6, 5, 4, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List\n",
        "from collections import OrderedDict\n",
        "def group_by_length(lst: List[str]) -> Dict[int, List[str]]:\n",
        "    \"\"\"\n",
        "    Groups the strings by their length and returns a dictionary.\n",
        "    \"\"\"\n",
        "    # Your code here\n",
        "    dict1 = {}\n",
        "    for i in lst:\n",
        "      if len(i) not in dict1:\n",
        "        dict1[len(i)]=[i]\n",
        "      else:\n",
        "        dict1[len(i)].append(i)\n",
        "    dict1 = dict(sorted(dict1.items()))\n",
        "    return dict1"
      ],
      "metadata": {
        "id": "It0BKkIW5Nhs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_by_length([\"apple\", \"bat\", \"car\", \"elephant\", \"dog\", \"bear\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxRSfqDu_ofR",
        "outputId": "f7f30e06-02d4-478a-eb28-23dea624ddf6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: ['bat', 'car', 'dog'], 4: ['bear'], 5: ['apple'], 8: ['elephant']}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Any\n",
        "def flatten_dict(nested_dict: Dict[str, Any], sep: str = '.') -> Dict[str, Any]:\n",
        "  def _flatten(current_dict: Dict[str, Any], parent_key: str) -> Dict[str, Any]:\n",
        "    new_dict = {}\n",
        "    for k, v in current_dict.items():\n",
        "      new_k = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "      if isinstance(v, dict):\n",
        "        new_dict.update(_flatten(v, new_k))\n",
        "      elif isinstance(v, list):\n",
        "        for i, item in enumerate(v):\n",
        "          list_key = f\"{new_k}[{i}]\"\n",
        "          if isinstance(item, dict):\n",
        "            new_dict.update(_flatten(item, list_key))\n",
        "          else:\n",
        "            new_dict[list_key] = item\n",
        "      else:\n",
        "        new_dict[new_k] = v\n",
        "    return new_dict\n",
        "\n",
        "  return _flatten(nested_dict, '')\n"
      ],
      "metadata": {
        "id": "ckNs27pQA6JG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_dict({\n",
        "    \"road\": {\n",
        "        \"name\": \"Highway 1\",\n",
        "        \"length\": 350,\n",
        "        \"sections\": [\n",
        "            {\n",
        "                \"id\": 1,\n",
        "                \"condition\": {\n",
        "                    \"pavement\": \"good\",\n",
        "                    \"traffic\": \"moderate\"\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"id\": 2,\n",
        "                \"condition\": {\n",
        "                    \"pavement\": \"poor\",\n",
        "                    \"traffic\": \"severe\"\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20WVIMS2Y57t",
        "outputId": "6335769e-1e33-452e-85d6-5e3388655e74"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'road.name': 'Highway 1',\n",
              " 'road.length': 350,\n",
              " 'road.sections[0].id': 1,\n",
              " 'road.sections[0].condition.pavement': 'good',\n",
              " 'road.sections[0].condition.traffic': 'moderate',\n",
              " 'road.sections[1].id': 2,\n",
              " 'road.sections[1].condition.pavement': 'poor',\n",
              " 'road.sections[1].condition.traffic': 'severe'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "def unique_permutations(nums: List[int]) -> List[List[int]]:\n",
        "  def backtrack(path, used):\n",
        "    if len(path) == len(nums):\n",
        "      result.append(path[:])\n",
        "      return\n",
        "    for i in range(len(nums)):\n",
        "      if used[i] or (i > 0 and nums[i] == nums[i - 1] and not used[i - 1]):\n",
        "        continue\n",
        "      used[i] = True\n",
        "      path.append(nums[i])\n",
        "      backtrack(path, used)\n",
        "      path.pop()\n",
        "      used[i] = False\n",
        "\n",
        "  nums.sort()\n",
        "  result = []\n",
        "  backtrack([], [False] * len(nums))\n",
        "  return result"
      ],
      "metadata": {
        "id": "wXL-jGcJY-cR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_permutations([0,2,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmqTki-1kzai",
        "outputId": "e931371f-9b27-4062-b80a-2c550a32965b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 1, 2], [0, 2, 1], [1, 0, 2], [1, 2, 0], [2, 0, 1], [2, 1, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def find_all_dates(text: str) -> List[str]:\n",
        "    res = []\n",
        "    lst = [r'\\b\\d{2}-\\d{2}-\\d{4}\\b', r'\\b\\d{2}/\\d{2}/\\d{4}\\b', r'\\b\\d{4}\\.\\d{2}\\.\\d{2}\\b']\n",
        "    for i in lst:\n",
        "      res.extend(re.findall(i, text))\n",
        "\n",
        "    return res"
      ],
      "metadata": {
        "id": "Wxz1a-xW8-mo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_all_dates(\"I was born on 23-08-1994, my friend on 08/23/1994, and another one on 1994.08.23.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv4mk62q_KQR",
        "outputId": "3fe3a6fe-fa39-4202-ec9b-77aa93d67f25"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['23-08-1994', '08/23/1994', '1994.08.23']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install polyline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4HvTqovDsxj",
        "outputId": "6194520b-b291-4f8c-ee6d-09b4f6c7bfe7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting polyline\n",
            "  Downloading polyline-2.0.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "Downloading polyline-2.0.2-py3-none-any.whl (6.0 kB)\n",
            "Installing collected packages: polyline\n",
            "Successfully installed polyline-2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import polyline\n",
        "import math\n",
        "\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6371000  # Radius of the Earth in meters\n",
        "    phi1 = math.radians(lat1)\n",
        "    phi2 = math.radians(lat2)\n",
        "    delta_phi = math.radians(lat2 - lat1)\n",
        "    delta_lambda = math.radians(lon2 - lon1)\n",
        "    a = math.sin(delta_phi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2) ** 2\n",
        "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
        "    return R * c\n",
        "def polyline_to_dataframe(polyline_str: str) -> pd.DataFrame:\n",
        "    coordinates = polyline.decode(polyline_str)\n",
        "    latitudes = []\n",
        "    longitudes = []\n",
        "    distances = [0]\n",
        "    for i, (lat, lon) in enumerate(coordinates):\n",
        "        latitudes.append(lat)\n",
        "        longitudes.append(lon)\n",
        "        if i > 0:\n",
        "            distance = haversine(latitudes[i - 1], longitudes[i - 1], lat, lon)\n",
        "            distances.append(distance)\n",
        "    df = pd.DataFrame({\n",
        "        'latitude': latitudes,\n",
        "        'longitude': longitudes,\n",
        "        'distance': distances\n",
        "    })\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "v3_Y6s2A_odw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "polyline_str = 'o~w~F`h~s@fC~dB'\n",
        "df = polyline_to_dataframe(polyline_str)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWm3mWPoqz7q",
        "outputId": "6c4b8cf3-8bbe-45aa-e6b6-9d311e46d3e5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   latitude  longitude     distance\n",
            "0  41.90712   -8.67985     0.000000\n",
            "1  41.90644   -8.69617  1352.674606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "def rotate_and_multiply_matrix(matrix: List[List[int]]) -> List[List[int]]:\n",
        "    n = len(matrix)\n",
        "\n",
        "    # Step 1: Rotate the matrix 90 degrees clockwise\n",
        "    rotated_matrix = [[0] * n for _ in range(n)]\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            rotated_matrix[j][n - 1 - i] = matrix[i][j]\n",
        "\n",
        "    # Step 2: Transform the rotated matrix\n",
        "    final_matrix = [[0] * n for _ in range(n)]\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            # Calculate the sum of the row and column excluding the current element\n",
        "            row_sum = sum(rotated_matrix[i]) - rotated_matrix[i][j]  # Exclude current element\n",
        "            col_sum = sum(rotated_matrix[k][j] for k in range(n)) - rotated_matrix[i][j]  # Exclude current element\n",
        "            final_matrix[i][j] = row_sum + col_sum\n",
        "\n",
        "    return final_matrix"
      ],
      "metadata": {
        "id": "NlouJihjDyoA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "result = rotate_and_multiply_matrix(matrix)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC0laz5Yq6dJ",
        "outputId": "0bf2f440-cb36-4463-eb21-8c1b214dc71b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[22, 19, 16], [23, 20, 17], [24, 21, 18]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "\n",
        "days_of_week = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "\n",
        "def day_time_to_datetime(day, time):\n",
        "    base_date = datetime(2023, 1, 2)\n",
        "    day_offset = days_of_week.index(day)\n",
        "    day_date = base_date + timedelta(days=day_offset)\n",
        "    time_obj = datetime.strptime(time, '%H:%M:%S').time()\n",
        "    return datetime.combine(day_date, time_obj)\n",
        "\n",
        "def time_check(df: pd.DataFrame) -> pd.Series:\n",
        "\n",
        "    def get_time_range(start_day, start_time, end_day, end_time):\n",
        "        start_dt = day_time_to_datetime(start_day, start_time)\n",
        "        end_dt = day_time_to_datetime(end_day, end_time)\n",
        "        return start_dt, end_dt\n",
        "\n",
        "    def check_coverage(group):\n",
        "        day_intervals = {day: [] for day in days_of_week}\n",
        "\n",
        "        for _, row in group.iterrows():\n",
        "            start_dt, end_dt = get_time_range(row['startDay'], row['startTime'], row['endDay'], row['endTime'])\n",
        "\n",
        "            while start_dt <= end_dt:\n",
        "                day_str = start_dt.strftime('%A')\n",
        "                day_intervals[day_str].append((start_dt.time(), end_dt.time()))\n",
        "                start_dt += timedelta(days=1)\n",
        "                start_dt = start_dt.replace(hour=0, minute=0, second=0)\n",
        "\n",
        "        for day, intervals in day_intervals.items():\n",
        "            intervals.sort()\n",
        "            merged = []\n",
        "            for start, end in intervals:\n",
        "                if not merged or merged[-1][1] < start:\n",
        "                    merged.append((start, end))\n",
        "                else:\n",
        "                    merged[-1] = (merged[-1][0], max(merged[-1][1], end))\n",
        "\n",
        "            if not merged or not (merged[0][0] == datetime.min.time() and merged[-1][1] == datetime.max.time()):\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    result = df.groupby(['id', 'id_2'], group_keys=False).apply(check_coverage)\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "esi28kDQFCYU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = pd.read_csv('/content/dataset-1.csv')\n",
        "time_check_results = time_check(df_1)\n",
        "\n",
        "print(time_check_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEYmjlnLNez3",
        "outputId": "f41afe01-8a4a-40c8-c336-c2cdcbe0b608"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id       id_2    \n",
            "1014000  -1          True\n",
            "1014002  -1          True\n",
            "1014003  -1          True\n",
            "1030000  -1          True\n",
            "          1030002    True\n",
            "                     ... \n",
            "1330016   1330006    True\n",
            "          1330008    True\n",
            "          1330010    True\n",
            "          1330012    True\n",
            "          1330014    True\n",
            "Length: 9254, dtype: bool\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-76f2382c8787>:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  result = df.groupby(['id', 'id_2'], group_keys=False).apply(check_coverage)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DACjQWdUpPic"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}